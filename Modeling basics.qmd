---
title: "Modeling_basics"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

### Ames Housing data

The tidy models book uses a dataset describing housing characteristics in Ames Iowa. The dataset has been modified a bit to make ot more useful in the tudyverse. The new form of the data is packaged in a package called modeldata. We can import that in the following code.

```{r}

library(modeldata) # This is also loaded by the tidymodels package
data(ames)

# or, in one line:
#data(ames, package = "modeldata")

dim(ames)
#> [1] 2930   74

#View(ames)


```

## 4.1 EXPLORING FEATURES OF HOMES IN AMES

Let's start our exploratory data analysis by focusing on the outcome we want to predict: the last sale price of the house (in USD). We can create a histogram to see the distribution of sale prices.

```{r}

library(tidymodels)
tidymodels_prefer()

```

```{r}

ggplot(ames, aes(x = Sale_Price)) + 
  geom_histogram(bins = 50, fill="forestgreen", col= "white")
```

This plot shows us that the data are right-skewed; there are more inexpensive houses than expensive ones. The median sale price was \$160,000, and the most expensive house was \$755,000. When modeling this outcome, a strong argument can be made that the price should be log-transformed. The advantages of this type of transformation are that no houses would be predicted with negative sale prices and that errors in predicting expensive houses will not have an undue influence on the model. Also, from a statistical perspective, a logarithmic transform may also stabilize the variance in a way that makes inference more legitimate. We can use similar steps to now visualize the transformed data.

```{r}
ggplot(ames, aes(x = Sale_Price)) + 
  geom_histogram(bins = 50, fill = "red", col= "white") +
  scale_x_log10()
```

Despite some drawbacks, the models used in this book use the log transformation for this outcome. *From this point on*, the outcome column is prelogged in the `ames` data frame:

```{r}
#converting price to log scale

ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
```

Another important aspect of these data for our modeling is their geographic locations. This spatial information is contained in the data in two ways: a qualitative `Neighborhood` label as well as quantitative longitude and latitude data. To visualize the spatial information, let's use both together to plot the data on a map.

The maps show some location patterns that might affect the modeling process (see book for details).

As described in Chapter [1](https://www.tmwr.org/software-modeling#software-modeling), it is critical to conduct exploratory data analysis prior to beginning any modeling. These housing data have characteristics that present interesting challenges about how the data should be processed and modeled. We describe many of these in later chapters. Some basic questions that could be examined during this exploratory stage include:

-   Is there anything odd or noticeable about the distributions of the individual predictors? Is there much skewness or any pathological distributions?

-   Are there high correlations between predictors? For example, there are multiple predictors related to house size. Are some redundant?

-   Are there associations between predictors and the outcomes?

Many of these questions will be revisited as these data are used throughout this book.

### Splitting the data

```{r}


# Set the random number stream using `set.seed()` so that the results can be 
# reproduced later. 
set.seed(501)

# Save the split information for an 80/20 split of the data.  80% training 20 testing.
ames_split <- initial_split(ames, prop = 0.80)
ames_split
#> <Training/Testing/Total>
#> <2344/586/2930>
```

The printed information denotes the amount of data in the training set (n=2,344=2,344), the amount in the test set (n=586=586), and the size of the original pool of samples (n=2,930=2,930).

The object `ames_split` is an `rsplit` object and contains only the partitioning information; to get the resulting data sets, we apply two more functions - training() and testing().

```{r}

ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)

dim(ames_train)
#> [1] 2344   74

dim(ames_test)
```

These objects are data frames with the same columns as the original data but only the appropriate rows for each set.

As discussed in Chapter [4](https://www.tmwr.org/ames#ames), the sale price distribution is right-skewed, with proportionally more inexpensive houses than expensive houses on either side of the center of the distribution. The worry here with simple splitting is that the more expensive houses would not be well represented in the training set; this would increase the risk that our model would be ineffective at predicting the price for such properties. The dotted vertical lines in Figure [5.1](https://www.tmwr.org/splitting#fig:ames-sale-price) indicate the four quartiles for these data. A stratified random sample would conduct the 80/20 split within each of these data subsets and then pool the results. In **rsample**, this is achieved using the `strata` argument:

```{r}
set.seed(502)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)

dim(ames_train)
#> [1] 2342   74
```

Can also split into three sets. Training, testing and validation. Using the initial_validation_split function. The validation set is used as an interim test set as the model is developed while still retaining the test set for final testing of the model. This is covered more in Ch 10.

# 6 Fitting Models with parsnip

The **parsnip** package, one of the R packages that are part of the **tidymodels** metapackage, provides a fluent and standardized interface for a variety of different models. In this chapter, we give some motivation for why a common interface is beneficial for understanding and building models in practice and show how to use the **parsnip** package.

Specifically, we will focus on how to `fit()` and `predict()` directly with a **parsnip** object, which may be a good fit for some straightforward modeling problems. The next chapter illustrates a better approach for many modeling tasks by combining models and preprocessors together into something called a `workflow` object.

For tidymodels, the approach to specifying a model is intended to be more unified:

1.  *Specify the type of model based on its mathematical structure* (e.g., linear regression, random forest, KNN, etc).

2.  *Specify the engine for fitting the model.* Most often this reflects the software package that should be used, like Stan or **glmnet**. These are models in their own right, and **parsnip** provides consistent interfaces by using these as engines for modeling.

3.  *When required, declare the mode of the model.* The mode reflects the type of prediction outcome. For numeric outcomes, the mode is regression; for qualitative outcomes, it is classification.^[14](https://www.tmwr.org/models#fn14)^ If a model algorithm can only address one type of prediction outcome, such as linear regression, the mode is already set.

These specifications are built without referencing the data. For example, for the three cases we outlined:

```{r}
#library(tidymodels)
#tidymodels_prefer()

linear_reg() %>% set_engine("lm")
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: lm

linear_reg() %>% set_engine("glmnet") 
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: glmnet

linear_reg() %>% set_engine("stan")
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: stan
```

Once the details of the model have been specified, the model estimation can be done with either the `fit()` function (to use a formula) or the `fit_xy()` function (when your data are already pre-processed). The **parsnip** package allows the user to be indifferent to the interface of the underlying model; you can always use a formula even if the modeling package's function only has the `x`/`y` interface.

The `translate()` function can provide details on how **parsnip** converts the user's code to the package's syntax:

```{r}
linear_reg() %>% set_engine("lm") %>% translate()
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: lm 
#> 
#> Model fit template:
#> stats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())

linear_reg(penalty = 1) %>% set_engine("glmnet") %>% translate()
#> Linear Regression Model Specification (regression)
#> 
#> Main Arguments:
#>   penalty = 1
#> 
#> Computational engine: glmnet 
#> 
#> Model fit template:
#> glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), 
#>     family = "gaussian")

linear_reg() %>% set_engine("stan") %>% translate()
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: stan 
#> 
#> Model fit template:
#> rstanarm::stan_glm(formula = missing_arg(), data = missing_arg(), 
#>     weights = missing_arg(), family = stats::gaussian, refresh = 0)
```

Note that `missing_arg()` is just a placeholder for the data that has yet to be provided.

Let's walk through how to predict the sale price of houses in the Ames data as a function of only longitude and latitude:

```{r}
lm_model <- 
  linear_reg() %>% 
  set_engine("lm")


lm_form_fit <- 
  lm_model %>% 
  # Recall that Sale_Price has been pre-logged
  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)

lm_xy_fit <- 
  lm_model %>% 
  fit_xy(
    x = ames_train %>% select(Longitude, Latitude),
    y = ames_train %>% pull(Sale_Price)
  )

lm_form_fit
#> parsnip model object
#> 
#> 
#> Call:
#> stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)
#> 
#> Coefficients:
#> (Intercept)    Longitude     Latitude  
#>     -302.97        -2.07         2.71
lm_xy_fit
#> parsnip model object
#> 
#> 
#> Call:
#> stats::lm(formula = ..y ~ ., data = data)
#> 
#> Coefficients:
#> (Intercept)    Longitude     Latitude  
#>     -302.97        -2.07         2.71
```

The above is demonstrating how to tun a model. First the model is set up:

lm_model \<- linear_reg() %\>% set_engine("lm"). This says to use linear regresssion and to use the lm method. This establishes the "settings" (my word) for how to do the model. lm_form_fit refers to the fact that this method uses a formula y \~ x.

lm_form_fit \<- lm_model %\>% \# Recall that Sale_Price has been pre-logged

fit(Sale_Price \~ Longitude + Latitude, data = ames_train)

This fits the data to the lm model. It feeds the lm model into the fit function, the formula is provided, and the train data is used. Results are saved in lm_form_fit variable.

next the same steps are done using fit_xy. This is a function to fit the model by supplying the x and y values, but doesn't use a formula. The point of this section is to show that both of these give the same result in this case. The result is a parsnip object that contains the results of the modeling.

What are the differences between `fit()` and `fit_xy()`? The `fit_xy()` function always passes the data as is to the underlying model function. It will not create dummy/indicator variables before doing so. When `fit()` is used with a model specification, this almost always means that dummy variables will be created from qualitative predictors. If the underlying function requires a matrix (like glmnet), it will make the matrix. However, if the underlying function uses a formula, `fit()` just passes the formula to that function. We estimate that 99% of modeling functions using formulas make dummy variables. The other 1% include tree-based methods that do not require purely numeric predictors. See Section [7.4](https://www.tmwr.org/workflows#workflow-encoding) for more about using formulas in tidymodels.[↩︎](https://www.tmwr.org/models#fnref15)

## 6.2 USE THE MODEL RESULTS

Once the model is created and fit, we can use the results in a variety of ways; we might want to plot, print, or otherwise examine the model output. Several quantities are stored in a **parsnip** model object, including the fitted model. This can be found in an element called `fit`, which can be returned using the `extract_fit_engine()` function:

```{r}
lm_form_fit %>% extract_fit_engine()
#> 
#> Call:
#> stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)
#> 
#> Coefficients:
#> (Intercept)    Longitude     Latitude  
#>     -302.97        -2.07         2.71
```

Normal methods can be applied to this object, such as printing and plotting: Below, the results are piped into the vcov function, which calculates the covariance and generates a cov matrix.

```{r}
lm_form_fit %>% extract_fit_engine() %>% vcov()
#>             (Intercept) Longitude Latitude
#> (Intercept)     207.311   1.57466 -1.42397
#> Longitude         1.575   0.01655 -0.00060
#> Latitude         -1.424  -0.00060  0.03254
```

```{r}
?vcov
```

Aside: what is vcov?

vcov: Description

Returns the variance-covariance matrix of the main parameters of a fitted model object. The "main" parameters of model correspond to those returned by [`coef`](https://c1f420f6fbba408a93be2a08c16fc196.app.posit.cloud/help/library/stats/help/coef)`.`

#### Using the broom package to tidy the output

The **broom** package can convert many types of model objects to a tidy structure. For example, using the `tidy()` method on the linear model produces:

```{r}
tidy(lm_form_fit)
#> # A tibble: 3 × 5
#>   term        estimate std.error statistic  p.value
#>   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
#> 1 (Intercept)  -303.      14.4       -21.0 3.64e-90
#> 2 Longitude      -2.07     0.129     -16.1 1.40e-55
#> 3 Latitude        2.71     0.180      15.0 9.29e-49
```

The column names are standardized across models and do not contain any additional data (such as the type of statistical test). The data previously contained in the row names are now in a column called `term`. One important principle in the tidymodels ecosystem is that a function should return values that are *predictable, consistent,* and *unsurprising*.

## 6.3 MAKE PREDICTIONS

Another area where **parsnip** diverges from conventional R modeling functions is the format of values returned from `predict()`. For predictions, **parsnip** always conforms to the following rules:

1.  The results are always a tibble.

2.  The column names of the tibble are always predictable.

3.  There are always as many rows in the tibble as there are in the input data set.

For example, when numeric data are predicted:

The code below is applying the fitted model to a small slize of th eoriginal ames data: rows 1 -5. This is predicting the sale price for these first 5 houses, using the predict function.

```{r}
ames_test_small <- ames_test %>% slice(1:5)
predict(lm_form_fit, new_data = ames_test_small)
#> # A tibble: 5 × 1
#>   .pred
#>   <dbl>
#> 1  5.22
#> 2  5.21
#> 3  5.28
#> 4  5.27
#> 5  5.28
```

Why the leading dot in some of the column names? Some tidyverse and tidymodels arguments and return values contain periods. This is to protect against merging data with duplicate names. There are some data sets that contain predictors named `pred`!

For comparison, here are the actual values ofr the first 5 houses

```{r}
head(ames$Sale_Price)
```

These three rules make it easier to merge predictions with the original data:

```{r}
ames_test_small %>% 
  select(Sale_Price) %>% 
  bind_cols(predict(lm_form_fit, ames_test_small)) %>% 
  # Add 95% prediction intervals to the results:
  bind_cols(predict(lm_form_fit, ames_test_small, type = "pred_int")) 
#> # A tibble: 5 × 4
#>   Sale_Price .pred .pred_lower .pred_upper
#>        <dbl> <dbl>       <dbl>       <dbl>
#> 1       5.02  5.22        4.91        5.54
#> 2       5.39  5.21        4.90        5.53
#> 3       5.28  5.28        4.97        5.60
#> 4       5.28  5.27        4.96        5.59
#> 5       5.28  5.28        4.97        5.60
```

## 7.2 WORKFLOW BASICS

The **workflows** package allows the user to bind modeling and preprocessing objects together. Let's start again with the Ames data and a simple linear model:

The **workflows** package allows the user to bind modeling and preprocessing objects together. Let's start again with the Ames data and a simple linear model:

```{r}
library(tidymodels)  # Includes the workflows package
tidymodels_prefer()

lm_model <- 
  linear_reg() %>% 
  set_engine("lm")
```

A workflow always requires a **parsnip** model object:

```{r}
lm_wflow <- 
  workflow() %>% 
  add_model(lm_model)

lm_wflow

```

Notice that we have not yet specified how this workflow should preprocess the data: `Preprocessor: None`.

If our model is very simple, a standard R formula can be used as a preprocessor:

```{r}
lm_wflow <- 
  lm_wflow %>% 
  add_formula(Sale_Price ~ Longitude + Latitude)

lm_wflow
```

Note - only run the above code once. Once a formula is added, an error occurs if you try to add it again.

Next - Workflows have require `fit()` method that can be used to create the model. Using the objects created in Section [6.6](https://www.tmwr.org/models#models-summary):

```{r}
lm_fit <- fit(lm_wflow, ames_train)
lm_fit
```

We can also `predict()` on the fitted workflow:

```{r}
predict(lm_fit, ames_test %>% slice(1:3)) #lm_fit contains the workflow
#> # A tibble: 3 × 1
#>   .pred
#>   <dbl>
#> 1  5.22
#> 2  5.21
#> 3  5.28
```

Both the model and preprocessor can be removed or updated:

```{r}
lm_fit %>% update_formula(Sale_Price ~ Longitude) 
lm_fit
```

Try to refit with modified formula

```{r}
lm_fit <- fit(lm_wflow, ames_train)
lm_fit
```

and predict

```{r}
predict(lm_fit, ames_test %>% slice(1:3))
```

doesn't seem to have changed anything. Maybe need to also update the preprocessor.

I'm abit confused on model vs preprocessor. vs formula. I uodated the formula, now there is the old and new preprocessors in the workflow.

## 7.3 ADDING RAW VARIABLES TO THE `workflow()`

There is another interface for passing data to the model, the `add_variables()` function, which uses a **dplyr**-like syntax for choosing variables. The function has two primary arguments: `outcomes` and `predictors`. These use a selection approach similar to the **tidyselect** backend of **tidyverse** packages to capture multiple selectors using `c()`.

```{r}
lm_wflow <- 
  lm_wflow %>% 
  remove_formula() %>% 
  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))
lm_wflow
#> ══ Workflow ═════════════════════════════════════════════════════════════════════════
#> Preprocessor: Variables
#> Model: linear_reg()
#> 
#> ── Preprocessor ─────────────────────────────────────────────────────────────────────
#> Outcomes: Sale_Price
#> Predictors: c(Longitude, Latitude)
#> 
#> ── Model ────────────────────────────────────────────────────────────────────────────
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: lm

```

The predictors could also have been specified using a more general selector, such as

```{r}
#predictors = c(ends_with("tude"))
```

One nicety is that any outcome columns accidentally specified in the predictors argument will be quietly removed. This facilitates the use of:

```{r}

#predictors = everything()

```

When the model is fit, the specification assembles these data, unaltered, into a data frame and passes it to the underlying function:

```{r}
fit(lm_wflow, ames_train)
```

If you would like the underlying modeling method to do what it would normally do with the data, `add_variables()` can be a helpful interface. As we will see in Section [7.4.1](https://www.tmwr.org/workflows#special-model-formulas), it also facilitates more complex modeling specifications. However, as we mention in the next section, models such as `glmnet` and `xgboost` expect the user to make indicator variables from factor predictors. In these cases, a recipe or formula interface will typically be a better choice.

In the next chapter, we will look at a more powerful preprocessor (called a *recipe*) that can also be added to a workflow.

## 7.4 HOW DOES A `workflow()` USE THE FORMULA?

Skipping overnthis part. Seems to complicated for me at the moment. The main gistis how workflows work with multi level models.

## 7.5 CREATING MULTIPLE WORKFLOWS AT ONCE

This section looks interesting. How to generate and compare many different models to find the best one.

In some situations, the data require numerous attempts to find an appropriate model. For example:

-   For predictive models, it is advisable to evaluate a variety of different model types. This requires the user to create multiple model specifications.

-   Sequential testing of models typically starts with an expanded set of predictors. This "full model" is compared to a sequence of the same model that removes each predictor in turn. Using basic hypothesis testing methods or empirical validation, the effect of each predictor can be isolated and assessed.

In these situations, as well as others, it can become tedious or onerous to create a lot of workflows from different sets of preprocessors and/or model specifications. To address this problem, the **workflowset** package creates combinations of workflow components. A list of preprocessors (e.g., formulas, **dplyr** selectors, or feature engineering recipe objects discussed in the next chapter) can be combined with a list of model specifications, resulting in a set of workflows.

As an example, let's say that we want to focus on the different ways that house location is represented in the Ames data. We can create a set of formulas that capture these predictors:

```{r}
location <- list(
  longitude = Sale_Price ~ Longitude,
  latitude = Sale_Price ~ Latitude,
  coords = Sale_Price ~ Longitude + Latitude,
  neighborhood = Sale_Price ~ Neighborhood
)
```

These representations can be crossed with one or more models using the `workflow_set()` function. We'll just use the previous linear model specification to demonstrate:

```{r}
library(workflowsets)
location_models <- workflow_set(preproc = location, models = list(lm = lm_model))
location_models
#> # A workflow set/tibble: 4 × 4
#>   wflow_id        info             option    result    
#>   <chr>           <list>           <list>    <list>    
#> 1 longitude_lm    <tibble [1 × 4]> <opts[0]> <list [0]>
#> 2 latitude_lm     <tibble [1 × 4]> <opts[0]> <list [0]>
#> 3 coords_lm       <tibble [1 × 4]> <opts[0]> <list [0]>
#> 4 neighborhood_lm <tibble [1 × 4]> <opts[0]> <list [0]>
location_models$info[[1]]
#> # A tibble: 1 × 4
#>   workflow   preproc model      comment
#>   <list>     <chr>   <chr>      <chr>  
#> 1 <workflow> formula linear_reg ""
extract_workflow(location_models, id = "coords_lm")
#> ══ Workflow ═════════════════════════════════════════════════════════════════════════
#> Preprocessor: Formula
#> Model: linear_reg()
#> 
#> ── Preprocessor ─────────────────────────────────────────────────────────────────────
#> Sale_Price ~ Longitude + Latitude
#> 
#> ── Model ────────────────────────────────────────────────────────────────────────────
#> Linear Regression Model Specification (regression)
#> 
#> Computational engine: lm
```

```{r}
#Extract the neighborhood model instead

extract_workflow(location_models, id = "neighborhood_lm")
```

Workflow sets are mostly designed to work with resampling, which is discussed in Chapter [10](https://www.tmwr.org/resampling#resampling). The columns `option` and `result` must be populated with specific types of objects that result from resampling. We will demonstrate this in more detail in Chapters [11](https://www.tmwr.org/compare#compare) and [15](https://www.tmwr.org/workflow-sets#workflow-sets).

In the meantime, let's create model fits for each formula and save them in a new column called `fit`. We'll use basic **dplyr** and **purrr** operations:

below:

location models is the workflow set that contains the 4 models.

info is a list within location models that contains info on each model.

mutate will create a new column (called fit) in location \_models

the fit function will fit ames_train data to each model

map applies this fit function to each model

not sure what .x\$workflow\[\[1\]\] refers to. But here's what I'm thinking : It is referring to the model to be fit in each case. I believe it is in location_models\$info\$workflow, first column. But I can't seem to access that directly. So location_models\$info is a list of 4 tibbles. each one has three columns: workflow, preproc, and model

map must automatically iterate over each element of the info list.

.x\$workflow refers to the workflow column in the info list (one for each of our models)

each workflow column itself contains a list. workflow\[\[1\]\] refers to the first element of that list.

workflow\[\[1\]\] must refer to the specific formula for each different model

```{r}
location_models <-
   location_models %>%
   mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train)))
location_models

location_models$fit[[3]] #this accesses the fit result for each model (in this case model 3)

```

## 7.6 EVALUATING THE TEST SET

Let's say that we've concluded our model development and have settled on a final model. There is a convenience function called `last_fit()` that will *fit* the model to the entire training set and *evaluate* it with the testing set.

Using `lm_wflow` as an example, we can pass the model and the initial training/testing split to the function:

so last_fit refers to the fact that this is the last step (as opposed to last as the most recent fit). It is fitting on the spli out training data and testing on the test data.

```{r}
final_lm_res <- last_fit(lm_wflow, ames_split)
final_lm_res
#> # Resampling results
#> # Manual resampling 
#> # A tibble: 1 × 6
#>   splits             id               .metrics .notes   .predictions .workflow 
#>   <list>             <chr>            <list>   <list>   <list>       <list>    
#> 1 <split [2342/588]> train/test split <tibble> <tibble> <tibble>     <workflow>

```

The `.workflow` column contains the fitted workflow and can be pulled out of the results using:

```{r}
fitted_lm_wflow <- extract_workflow(final_lm_res)
```

Similarly, `collect_metrics()` and `collect_predictions()` provide access to the performance metrics and predictions, respectively.

```{r}
collect_metrics(final_lm_res)
collect_predictions(final_lm_res) %>% slice(1:5)
```

## 7.7 CHAPTER SUMMARY

In this chapter, you learned that the modeling process encompasses more than just estimating the parameters of an algorithm that connects predictors to an outcome. This process also includes preprocessing steps and operations taken after a model is fit. We introduced a concept called a *model workflow* that can capture the important components of the modeling process. Multiple workflows can also be created inside of a *workflow set*. The `last_fit()` function is convenient for fitting a final model to the training set and evaluating with the test set.

For the Ames data, the related code that we\'ll see used again is:
